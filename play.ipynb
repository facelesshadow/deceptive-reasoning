{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec51c18",
   "metadata": {},
   "source": [
    "# Just a file to revise all langgraph topics needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f80a391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not much! Just hanging out, ready to chat. ðŸ˜Š \n",
      "\n",
      "What's up with *you*? Howâ€™s your day going?"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model='gemma3:1b')\n",
    "for chunk in model.stream('wassup'):\n",
    "    for char in chunk.content:\n",
    "        for c in char:\n",
    "            print(c, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf1e00",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c52894e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from typing import TypedDict, Literal, List, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016849d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateOne(TypedDict):\n",
    "    a: int\n",
    "    b: int\n",
    "    answer: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(state):\n",
    "    return ({'answer': state['a']+state['b']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ae27114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'answer': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(StateOne)\n",
    "\n",
    "builder.add_node(\"add\", add)\n",
    "\n",
    "builder.add_edge(START, \"add\")\n",
    "builder.add_edge('add', END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph.invoke({\"a\":1, \"b\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a3e80",
   "metadata": {},
   "source": [
    "## Conditional Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf29cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateOne(TypedDict):\n",
    "    a: int\n",
    "    b: int\n",
    "    answer: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8972d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(state):\n",
    "    return ({'answer': state['a']+state['b']})\n",
    "\n",
    "def sub(state):\n",
    "    return ({'answer': state['a']-state['b']})\n",
    "\n",
    "def condition(state) -> Literal['add', 'sub']:\n",
    "    if state['a'] > 5:\n",
    "        return \"sub\"\n",
    "    else:\n",
    "        return \"add\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b3d2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(StateOne)\n",
    "\n",
    "builder.add_node(\"add\", add)\n",
    "builder.add_node(\"sub\", sub)\n",
    "\n",
    "builder.add_conditional_edges(START, condition)\n",
    "builder.add_edge(\"sub\", END)\n",
    "builder.add_edge('add', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e67a9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0, 'b': 1, 'answer': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'a':0, 'b':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e0f0825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 5, 'b': 1, 'answer': 6}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'a':5, 'b':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc946fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 6, 'b': 1, 'answer': 5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'a':6, 'b':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2610d",
   "metadata": {},
   "source": [
    "## Parallels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "133d4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateOne(TypedDict):\n",
    "    a: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d41569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef condition(state) -> Literal[\\'node1\\', \\'node2\\']:\\n    if state[\\'a\\'] > 5:\\n        return \"sub\"\\n    else:\\n        return \"add'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add(state):\n",
    "    return ({'a': state['a']+\" Node 1\"})\n",
    "\n",
    "def sub(state):\n",
    "    return ({'new': state['answer']+\" Node 2\"})\n",
    "\"\"\"\n",
    "def condition(state) -> Literal['node1', 'node2']:\n",
    "    if state['a'] > 5:\n",
    "        return \"sub\"\n",
    "    else:\n",
    "        return \"add\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e53fd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(StateOne)\n",
    "\n",
    "builder.add_node(\"add\", add)\n",
    "builder.add_node(\"sub\", sub)\n",
    "\n",
    "builder.add_edge(START, \"add\")\n",
    "builder.add_edge(START, \"sub\")\n",
    "builder.add_edge(\"sub\", END)\n",
    "builder.add_edge('add', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae502e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'hello Node 1', 'answer': 'lol'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'a':\"hello\", \"answer\": \"lol\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abaeb29",
   "metadata": {},
   "source": [
    "**Each Parallel Node** can update induvidual / different keys, but to update the same key - Reducer needed.\n",
    "\n",
    "**If a key which is not in the state** is updated, the end state **DOES NOT** include it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f08d8",
   "metadata": {},
   "source": [
    "### Reducers for parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ea69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateOne(TypedDict):\n",
    "    answer: Annotated[list[int], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b78fb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"answer\": [state['answer'][0] + 1]}\n",
    "\n",
    "\n",
    "builder = StateGraph(StateOne)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", END)\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdcb6991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': [1, 2]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'answer': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91d7064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"---Node 1---\")\n",
    "    return {\"answer\": [state['answer'][-1] + 1]}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"---Node 2---\")\n",
    "    return {\"answer\": [state['answer'][-1] + 1]}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"---Node 3---\")\n",
    "    return {\"answer\": [state['answer'][-1] + 10]}\n",
    "\n",
    "builder = StateGraph(StateOne)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_edge(\"node_1\", \"node_2\")\n",
    "builder.add_edge(\"node_1\", \"node_3\")\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "\n",
    "# Add\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "110af8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Node 1---\n",
      "---Node 2---\n",
      "---Node 3---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': [0, 1, 2, 11]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'answer':[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59524475",
   "metadata": {},
   "source": [
    "## Human In The Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "97f79a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    answers: Annotated[List[Literal[\"Yes\", \"No\"]], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91af64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model='gemma3:1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a3e4f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    response: Literal[\"Yes\", \"No\"]\n",
    "\n",
    "llm_structured = model.with_structured_output(Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a38cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(response='Yes')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"You are given a query / question. If you understand the query and know about it, Reply with \"Yes\". If you don't have full clarity on the query, or if you don't know about the topic asked, simply return a \"No\".\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "llm_structured.invoke([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "980c2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('assistant', assistant)\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a637a4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Do you know about jldfjs', additional_kwargs={}, response_metadata={}, id='9d9aa426-d62e-42f0-8cd0-14467fb5f436'),\n",
       "  HumanMessage(content='No', additional_kwargs={}, response_metadata={}, id='6e984e4b-2ad4-4e1b-a629-ad860f3ec1c8')],\n",
       " 'answers': []}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages': HumanMessage(content=\"Do you know about jldfjs\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "93475b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Literal\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    response: Literal[\"Yes\", \"No\"]\n",
    "\n",
    "llm_structured = model.with_structured_output(Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e425123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    answers: Annotated[List[Literal[\"Yes\", \"No\"]], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a101903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state):\n",
    "    prompt = \"\"\"You are given a query / question. If you understand the query and know about it, Reply with \"Yes\". If you don't have full clarity on the query, or if you don't know about the topic asked, simply return a \"No\".\n",
    "    \"\"\"\n",
    "    answer = llm_structured.invoke([SystemMessage(content=prompt), state['messages'][-1]])\n",
    "    return ({'answers': [answer.response]})\n",
    "\n",
    "def check(state) -> Literal['__end__', 'fallback']:\n",
    "    if(state['answers'][-1] == 'Yes'):\n",
    "        return \"__end__\"\n",
    "    elif(state['answers'][-1] == 'No'):\n",
    "        return 'fallback'\n",
    "    \n",
    "def fallback(state):\n",
    "    user_input = input(f\"Could you please rephrase your question '{state['messages'][-1].content}'\")\n",
    "    return ({'messages': HumanMessage(content=user_input)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d652cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('assistant', assistant)\n",
    "builder.add_node('fallback', fallback)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", check)\n",
    "builder.add_edge(\"fallback\", \"assistant\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4c917b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Do you know about jldfjs', additional_kwargs={}, response_metadata={}, id='db71945c-58bd-4562-979e-0e83f529e991'),\n",
       "  HumanMessage(content='I mean Dark Matter', additional_kwargs={}, response_metadata={}, id='95175362-4121-443b-8671-f1865a8993d6')],\n",
       " 'answers': ['No', 'Yes']}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages': HumanMessage(content=\"Do you know about jldfjs\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7e80ee20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Do you know about jldfjs', additional_kwargs={}, response_metadata={}, id='ffeffe4d-9914-4f71-ba4c-5f2c1c332815'),\n",
       "  HumanMessage(content='Do you know about dark matter', additional_kwargs={}, response_metadata={}, id='59b23813-592a-4afe-8ed1-46802192b731')],\n",
       " 'answers': ['No', 'Yes']}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages': HumanMessage(content=\"Do you know about jldfjs\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d4ed12f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Do you know about Dark matter', additional_kwargs={}, response_metadata={}, id='a2f7c70e-a230-41bd-acaa-28dcdbaaaba1')],\n",
       " 'answers': ['Yes']}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages': HumanMessage(content=\"Do you know about Dark matter\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4db44671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Do you know about modified newtonian dynamics', additional_kwargs={}, response_metadata={}, id='5c07924e-8296-48c3-a34a-848e9b6acfe6'),\n",
       "  HumanMessage(content='Mond is the alternative for Dark matter, Modified newtonian dynamics', additional_kwargs={}, response_metadata={}, id='44e80bef-7894-4443-b002-b81030ba0f15'),\n",
       "  HumanMessage(content='Mond', additional_kwargs={}, response_metadata={}, id='ec4938d5-549a-4ad2-906b-96286093ac54')],\n",
       " 'answers': ['No', 'No', 'Yes']}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'messages': HumanMessage(content=\"Do you know about modified newtonian dynamics\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366aec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
